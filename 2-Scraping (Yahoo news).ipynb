{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports and other high-level configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71UGWbbKPD0k",
        "outputId": "8ce81fd2-8410-4326-cf0d-1258720fa0a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\udayk\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\udayk\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import config\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "companies = config.companies_of_interest\n",
        "df = pd.DataFrame()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The following cell collects data from Yahoo news about our companies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search results for Twitter:\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "--------------------------\n",
            "Search results for Ebix:\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "--------------------------\n",
            "Search results for Block:\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "--------------------------\n",
            "Search results for Loki:\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "--------------------------\n",
            "Search results for Blockchain:\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "--------------------------\n",
            "Search results for Nikola:\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "--------------------------\n",
            "Search results for Adani:\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "--------------------------\n",
            "Search results for Block:\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "--------------------------\n",
            "Search results for Kandi:\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "--------------------------\n",
            "Search results for Lordstown:\n",
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "--------------------------\n"
          ]
        }
      ],
      "source": [
        "for company in companies:\n",
        "    yahoo_url = f\"https://news.search.yahoo.com/search?p={company}\"\n",
        "    yahoo_response = requests.get(yahoo_url)\n",
        "    yahoo_soup = BeautifulSoup(yahoo_response.content, \"html.parser\")\n",
        "\n",
        "    yahoo_titles = yahoo_soup.find_all(\"h4\", class_=\"s-title\")\n",
        "    yahoo_summaries = yahoo_soup.find_all(\"p\", class_=\"s-desc\")\n",
        "\n",
        "    yahoo_results = []\n",
        "\n",
        "    for i in range(len(yahoo_titles)):\n",
        "        title = yahoo_titles[i].text.strip()\n",
        "        summary = yahoo_summaries[i].text.strip()\n",
        "        yahoo_results.append({\"title\": title, \"summary\": summary, \"source\": \"Yahoo News\", \"company\": company})\n",
        "\n",
        "    # Create dataframe\n",
        "    results = yahoo_results \n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    print(f\"Search results for {company}:\")\n",
        "    print(df.head())\n",
        "    print(\"--------------------------\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizations of scrapped data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'title'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'title'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(results)\n\u001b[0;32m     20\u001b[0m \u001b[39m# Join all titles and summaries into a single string\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(df[\u001b[39m\"\u001b[39;49m\u001b[39mtitle\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mtolist() \u001b[39m+\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mtolist())\n\u001b[0;32m     23\u001b[0m \u001b[39m# Split the text into individual words\u001b[39;00m\n\u001b[0;32m     24\u001b[0m words \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39msplit()\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[1;31mKeyError\u001b[0m: 'title'"
          ]
        }
      ],
      "source": [
        "for company in config.companies_of_interest:\n",
        "    yahoo_url = f\"https://news.search.yahoo.com/search?p={company}\"\n",
        "    yahoo_response = requests.get(yahoo_url)\n",
        "    yahoo_soup = BeautifulSoup(yahoo_response.content, \"html.parser\")\n",
        "\n",
        "    yahoo_titles = yahoo_soup.find_all(\"h4\", class_=\"s-title\")\n",
        "    yahoo_summaries = yahoo_soup.find_all(\"p\", class_=\"s-desc\")\n",
        "\n",
        "    yahoo_results = []\n",
        "\n",
        "    for i in range(len(yahoo_titles)):\n",
        "        title = yahoo_titles[i].text.strip()\n",
        "        summary = yahoo_summaries[i].text.strip()\n",
        "        yahoo_results.append({\"title\": title, \"summary\": summary, \"source\": \"Yahoo News\", \"company\": company})\n",
        "\n",
        "    # Create dataframe\n",
        "    results = yahoo_results \n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    # Join all titles and summaries into a single string\n",
        "    text = \" \".join(df[\"title\"].tolist() + df[\"summary\"].tolist())\n",
        "\n",
        "    # Split the text into individual words\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word.lower() not in stop_words]\n",
        "    # Count the frequency of each word\n",
        "    word_counts = Counter(words)\n",
        "\n",
        "    # Create a bar chart of the 20 most common words\n",
        "    most_common_words = word_counts.most_common(20)\n",
        "    x = [word[0] for word in most_common_words]\n",
        "    y = [word[1] for word in most_common_words]\n",
        "    plt.bar(x, y)\n",
        "    plt.title(f\"Frequency of Words in Yahoo News Search Results for {company}\")\n",
        "    plt.xlabel(\"Word\")\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.savefig(f\"frequency of words-{company}.png\", dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"---------------------------------------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "08roIpjoAZPe",
        "outputId": "8ccb8e23-c1d5-4cdc-ec53-dea1aee6218f"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "user_input = input(\"Enter your search query: \")\n",
        "\n",
        "# Yahoo News search\n",
        "yahoo_url = f\"https://news.search.yahoo.com/search?p={user_input}\"\n",
        "yahoo_response = requests.get(yahoo_url)\n",
        "yahoo_soup = BeautifulSoup(yahoo_response.content, \"html.parser\")\n",
        "\n",
        "yahoo_titles = yahoo_soup.find_all(\"h4\", class_=\"s-title\")\n",
        "yahoo_summaries = yahoo_soup.find_all(\"p\", class_=\"s-desc\")\n",
        "\n",
        "yahoo_results = []\n",
        "\n",
        "# Remove stop words from titles and summaries\n",
        "stop_words = set(stopwords.words('english'))\n",
        "for i in range(len(yahoo_titles)):\n",
        "    title = yahoo_titles[i].text.strip()\n",
        "    summary = yahoo_summaries[i].text.strip()\n",
        "\n",
        "    title_words = title.split()\n",
        "    title = \" \".join([word for word in title_words if word.lower() not in stop_words])\n",
        "\n",
        "    summary_words = summary.split()\n",
        "    summary = \" \".join([word for word in summary_words if word.lower() not in stop_words])\n",
        "\n",
        "    yahoo_results.append({\"title\": title, \"summary\": summary, \"source\": \"Yahoo News\"})\n",
        "\n",
        "# Create dataframe\n",
        "results = yahoo_results\n",
        "df_1 = pd.DataFrame(results)\n",
        "\n",
        "# Data visualization\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(y=\"title\", data=df_1)\n",
        "plt.xlabel(\"Number of Articles\")\n",
        "plt.ylabel(\"Article Title\")\n",
        "plt.title(\"Yahoo News Search Results for: \" + user_input)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "tmAveKoKqgxd",
        "outputId": "0b1a7781-1f07-4442-a985-6e356005d705"
      },
      "outputs": [],
      "source": [
        "df_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "RjguYtodqsk0",
        "outputId": "e52f9234-6c3d-43b6-c2d0-c03ae9a1e5b9"
      },
      "outputs": [],
      "source": [
        "text = \" \".join(df[\"title\"].tolist() + df_1[\"summary\"].tolist())\n",
        "\n",
        "# Split the text into individual words\n",
        "words = text.split()\n",
        "\n",
        "# Count the frequency of each word\n",
        "word_counts = Counter(words)\n",
        "\n",
        "# Create a bar chart of the 20 most common words\n",
        "most_common_words = word_counts.most_common(20)\n",
        "x = [word[0] for word in most_common_words]\n",
        "y = [word[1] for word in most_common_words]\n",
        "plt.bar(x, y)\n",
        "plt.title(\"Frequency of Words in Yahoo News Search Results\")\n",
        "plt.xlabel(\"Word\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tSoW2EKAeYt",
        "outputId": "a19d3886-6e1f-46f4-a5c2-93abafd40d05"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "search_term = input(\"Enter a search term: \")\n",
        "# Get user input for the URL\n",
        "url = f'https://hindenburgresearch.com/{search_term}'\n",
        "response = requests.get(url)\n",
        "# Send a GET request to the URL and parse the HTML content\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Extract all headers and their related paragraphs\n",
        "headers = {}\n",
        "current_header = None\n",
        "for element in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p']):\n",
        "    if element.name.startswith('h'):\n",
        "        # If a new header is found, update the current header\n",
        "        current_header = element.text.strip()\n",
        "        headers[current_header] = []\n",
        "    elif current_header is not None:\n",
        "        # If a paragraph is found, add it to the list of paragraphs for the current header\n",
        "        headers[current_header].append(element.text.strip())\n",
        "\n",
        "# Create a list of dictionaries with the title, summary and source information\n",
        "data = []\n",
        "for header, paragraphs in headers.items():\n",
        "    data.append({\n",
        "        'title': header,\n",
        "        'summary': ' '.join(paragraphs),\n",
        "        'source': url\n",
        "    })\n",
        "\n",
        "# Create a dataframe from the list of dictionaries\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Print the dataframe\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "ILB1b5bLA6z9",
        "outputId": "f4e9c3d5-2fca-476a-dbf2-1d987c57ad7d"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(y=\"title\", data=df)\n",
        "plt.xlabel(\"Number of Articles\")\n",
        "plt.ylabel(\"Article Title\")\n",
        "plt.title(\"Yahoo News Search Results for: \" + user_input)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "5O13a6Z7FZpE",
        "outputId": "4ee57a28-cf99-4eee-e516-9537bf0732cc"
      },
      "outputs": [],
      "source": [
        "text = \" \".join(df[\"title\"].tolist() + df[\"summary\"].tolist())\n",
        "\n",
        "# Split the text into individual words\n",
        "words = text.split()\n",
        "\n",
        "# Count the frequency of each word\n",
        "word_counts = Counter(words)\n",
        "\n",
        "# Create a bar chart of the 20 most common words\n",
        "most_common_words = word_counts.most_common(20)\n",
        "x = [word[0] for word in most_common_words]\n",
        "y = [word[1] for word in most_common_words]\n",
        "plt.bar(x, y)\n",
        "plt.title(\"Frequency of Words in Yahoo News Search Results\")\n",
        "plt.xlabel(\"Word\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "wdLfox4PFhBk",
        "outputId": "93bfede5-e763-4647-afde-88881dffe90c"
      },
      "outputs": [],
      "source": [
        "df['summary'] = df['summary'].apply(lambda x: ' '.join([word for word in x.lower().split() if word not in stop_words]))\n",
        "\n",
        "# Count word frequency in summary column\n",
        "word_counts = Counter()\n",
        "df['summary'].str.split().apply(word_counts.update)\n",
        "\n",
        "# Plot word frequency\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(*zip(*word_counts.most_common(10)))\n",
        "plt.title('Most common words in article summaries')\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "ry9YwPeZGYd9",
        "outputId": "f6241e34-a285-464d-bec1-5a6021ffffe9"
      },
      "outputs": [],
      "source": [
        "df['title'] = df['title'].apply(lambda x: ' '.join([word for word in x.lower().split() if word not in stop_words]))\n",
        "\n",
        "# Count word frequency in summary column\n",
        "word_counts = Counter()\n",
        "df['title'].str.split().apply(word_counts.update)\n",
        "\n",
        "# Plot word frequency\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(*zip(*word_counts.most_common(10)))\n",
        "plt.title('Most common words in article summaries')\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "y4wzx8AqGl-U",
        "outputId": "257e33ae-6e10-4c65-c0d9-d9647c522529"
      },
      "outputs": [],
      "source": [
        "df_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "H5uO3RVCIHyt",
        "outputId": "ba589574-0d4e-46bf-96a5-c7fc01c46eba"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-vYy1NVIIVD"
      },
      "outputs": [],
      "source": [
        "result = pd.concat([df_1, df], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SCCsWVscIR5s",
        "outputId": "ab115ec5-f42c-479d-aade-9557a1983207"
      },
      "outputs": [],
      "source": [
        "result.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871
        },
        "id": "7s8krYfjIW-d",
        "outputId": "e788095b-ca29-4331-8cda-a0edd47afc6b"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "# Combine the 'title' and 'summary' columns into one\n",
        "text = ' '.join(result['title']) + ' ' + ' '.join(result['summary'])\n",
        "\n",
        "# Generate a word cloud for the combined text\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "\n",
        "# Plot the word cloud for the title column\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(WordCloud(width=800, height=400, background_color='white').generate(' '.join(df['title'])))\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud for Title Column')\n",
        "plt.show()\n",
        "\n",
        "# Plot the word cloud for the summary column\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(WordCloud(width=800, height=400, background_color='white').generate(' '.join(df['summary'])))\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud for Summary Column')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "U_uQvFHdIuWD",
        "outputId": "b37a85b7-85b4-4b6a-bb7e-ade6976d9e63"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "# Concatenate title and summary columns into one string\n",
        "text = ' '.join(result['title'].tolist() + result['summary'].tolist())\n",
        "\n",
        "# Remove stop words\n",
        "stop_words = ['the', 'and', 'of', 'in', 'to', 'a', 'that', 'for', 'is', 'on', 'with', 'it', 'this', 'as', 'an', 'be', 'by', 'from']\n",
        "words = [word for word in text.split() if word.lower() not in stop_words]\n",
        "\n",
        "# Count the frequency of each word\n",
        "word_counts = Counter(words)\n",
        "\n",
        "# Get the top 10 most common words\n",
        "top_words = word_counts.most_common(10)\n",
        "\n",
        "# Create a bar plot of the top 10 words\n",
        "plt.bar([word[0] for word in top_words], [word[1] for word in top_words])\n",
        "plt.title('Top 10 Most Common Words in Titles and Summaries')\n",
        "plt.xlabel('Word')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "piuan8aHJzXG",
        "outputId": "9b57fdd8-584a-4038-b651-b30c218684ea"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "\n",
        "# Create a list with all the words in the title column\n",
        "all_title_words = [word for title in result['title'] for word in title.split()]\n",
        "\n",
        "# Count the frequency of each word\n",
        "title_word_freq = Counter(all_title_words)\n",
        "\n",
        "# Get the top 10 most frequent words and their frequencies\n",
        "top_title_words = title_word_freq.most_common(10)\n",
        "x_title, y_title = zip(*top_title_words)\n",
        "\n",
        "# Convert the lists to a pandas series\n",
        "x_title = pd.Series(x_title)\n",
        "y_title = pd.Series(y_title)\n",
        "\n",
        "# Create a barplot with seaborn\n",
        "sns.barplot(x=y_title, y=x_title)\n",
        "plt.title('Top 10 most frequent words in title column')\n",
        "plt.xlabel('Frequency')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjoLvuGfLXAc"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Get stop words and set up punctuation filter\n",
        "stop_words = set(stopwords.words('english'))\n",
        "punctuation = set(string.punctuation)\n",
        "extra_symbols = set(['‘', '’', '“', '”', '’s', '’t', '—', '–', '...'])\n",
        "\n",
        "# Remove stop words and extra symbols from title column\n",
        "result['title_clean'] = result['title'].apply(lambda x: ' '.join(word.lower() for word in word_tokenize(x) if word.lower() not in stop_words and word.lower() not in punctuation and word.lower() not in extra_symbols))\n",
        "\n",
        "# Remove stop words and extra symbols from summary column\n",
        "result['summary_clean'] = result['summary'].apply(lambda x: ' '.join(word.lower() for word in word_tokenize(x) if word.lower() not in stop_words and word.lower() not in punctuation and word.lower() not in extra_symbols))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "0CkRre4pLcAU",
        "outputId": "8b67d396-187c-48a5-aa1e-3153bc71a812"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "6zKiRn83L7VV",
        "outputId": "c2b270d3-f34e-4ab4-be81-2eb2e4c1c600"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "# Concatenate title and summary columns into one string\n",
        "text = ' '.join(result['title_clean'].tolist() + result['summary_clean'].tolist())\n",
        "\n",
        "# Remove stop words\n",
        "stop_words = ['the', 'and', 'of', 'in', 'to', 'a', 'that', 'for', 'is', 'on', 'with', 'it', 'this', 'as', 'an', 'be', 'by', 'from']\n",
        "words = [word for word in text.split() if word.lower() not in stop_words]\n",
        "\n",
        "# Count the frequency of each word\n",
        "word_counts = Counter(words)\n",
        "\n",
        "# Get the top 10 most common words\n",
        "top_words = word_counts.most_common(10)\n",
        "\n",
        "# Create a bar plot of the top 10 words\n",
        "plt.bar([word[0] for word in top_words], [word[1] for word in top_words])\n",
        "plt.title('Top 10 Most Common Words in Titles and Summaries')\n",
        "plt.xlabel('Word')\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "AsUAGZekMD9V",
        "outputId": "dd3f26e7-8884-4f73-9800-9cf98e8da6de"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "\n",
        "# Create a list with all the words in the title column\n",
        "all_title_words = [word for title in result['title_clean'] for word in title.split()]\n",
        "\n",
        "# Count the frequency of each word\n",
        "title_word_freq = Counter(all_title_words)\n",
        "\n",
        "# Get the top 10 most frequent words and their frequencies\n",
        "top_title_words = title_word_freq.most_common(10)\n",
        "x_title, y_title = zip(*top_title_words)\n",
        "\n",
        "# Convert the lists to a pandas series\n",
        "x_title = pd.Series(x_title)\n",
        "y_title = pd.Series(y_title)\n",
        "\n",
        "# Create a barplot with seaborn\n",
        "sns.barplot(x=y_title, y=x_title)\n",
        "plt.title('Top 10 most frequent words in title column')\n",
        "plt.xlabel('Frequency')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "1ZBFnpTnMV3F",
        "outputId": "2ada16a2-8b2e-4413-b6f6-931713aeea96"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "\n",
        "# Create a list with all the words in the title column\n",
        "all_summary_words = [word for title in result['summary_clean'] for word in title.split()]\n",
        "\n",
        "# Count the frequency of each word\n",
        "title_word_freq = Counter(all_summary_words)\n",
        "\n",
        "# Get the top 10 most frequent words and their frequencies\n",
        "top_title_words = title_word_freq.most_common(10)\n",
        "x_title, y_title = zip(*top_title_words)\n",
        "\n",
        "# Convert the lists to a pandas series\n",
        "x_title = pd.Series(x_title)\n",
        "y_title = pd.Series(y_title)\n",
        "\n",
        "# Create a barplot with seaborn\n",
        "sns.barplot(x=y_title, y=x_title)\n",
        "plt.title('Top 10 most frequent words in summary column')\n",
        "plt.xlabel('Frequency')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "KWE-7xljMlm8",
        "outputId": "787a2dce-48e9-4b99-c035-0ba1c280985e"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "title_lengths = result['title_clean'].str.len()\n",
        "summary_lengths = result['summary_clean'].str.len()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(title_lengths, summary_lengths)\n",
        "plt.title('Title vs. Summary Lengths')\n",
        "plt.xlabel('Title Length (Characters)')\n",
        "plt.ylabel('Summary Length (Characters)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print the info() method\n",
        "print(df_1.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print the describe() method\n",
        "print(df_1.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print the head() method\n",
        "print(df_1.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print the tail() method\n",
        "print(df_1.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "HC0DCdnqNMRC",
        "outputId": "1c8151b0-2d8f-4146-b793-750ac7345f75"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "result['length'] = result['title_clean'].str.len() + result['summary_clean'].str.len()\n",
        "df_1['length'] = df_1['summary'].apply(len)\n",
        "sns.barplot(x=df_1.index, y='length', data=df_1)\n",
        "plt.title('Length of Articles')\n",
        "plt.xlabel('Article Index')\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel('Length (Characters)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "S49QBlJHNUNJ",
        "outputId": "bf8198b5-9b03-4220-dec2-cac51f81b7d0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "source_counts = result['source'].value_counts()\n",
        "labels = source_counts.index.tolist()\n",
        "sizes = source_counts.values.tolist()\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
        "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.title('Sources of Articles')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "X9GBGni_Nil8",
        "outputId": "4d8cdce7-be96-43d0-ac86-0ed33f9856ff"
      },
      "outputs": [],
      "source": [
        "result.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEWXTcORO_RN",
        "outputId": "406638ae-3bd4-420d-8061-c2182e19e299"
      },
      "outputs": [],
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9rowB5HQU0k"
      },
      "outputs": [],
      "source": [
        "def get_sentiment_scores(text):\n",
        "    sid = SentimentIntensityAnalyzer()\n",
        "    scores = sid.polarity_scores(text)\n",
        "    return scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_1['title_sentiment'] = df_1['title'].apply(get_sentiment_scores)\n",
        "df_1['summary_sentiment'] = df_1['summary'].apply(get_sentiment_scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4Se-ZVUQZ0m",
        "outputId": "0dff840b-a06c-47af-9a08-55e3aaa434f2"
      },
      "outputs": [],
      "source": [
        "title_sentiment_avg = df_1['title_sentiment'].apply(lambda x: x['compound']).mean()\n",
        "summary_sentiment_avg = df_1['summary_sentiment'].apply(lambda x: x['compound']).mean()\n",
        "\n",
        "print(\"Title sentiment average:\", title_sentiment_avg)\n",
        "print(\"Summary sentiment average:\", summary_sentiment_avg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKMd_wsfSMHd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
